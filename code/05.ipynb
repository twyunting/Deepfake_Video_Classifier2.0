{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"05.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1bw-hJ2yRxhClSvh1w_rXKN-CXYI2Iy8D","authorship_tag":"ABX9TyOynj7eECouEgWGCLyHO72n"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"d_sBIyCzTK-M"},"source":["# Install the required packages"]},{"cell_type":"code","metadata":{"id":"4uulU_UfxDnx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637447070175,"user_tz":300,"elapsed":432,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}},"outputId":"5a792b04-3dc8-445d-dc54-5c810fb405bb"},"source":["import sys\n","import os\n","import glob\n","import matplotlib.pyplot as plt\n","\n","import numpy as np\n","#to work with text files\n","import pandas as pd \n","\n","#pre-processing imports\n","from nltk.tokenize import word_tokenize\n","from nltk.tokenize import TweetTokenizer\n","from nltk.corpus import stopwords\n","from string import punctuation\n","import nltk\n","nltk.download('stopwords') # stopword \n","nltk.download('punkt') # word_tokenize\n","\n","#imports related to modeling\n","import numpy as np\n","from gensim.models import Word2Vec, KeyedVectors\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report"],"execution_count":81,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"markdown","metadata":{"id":"tOydEFAqB_Hn"},"source":["# word2vec installation"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ccuMIl5zB97T","executionInfo":{"status":"ok","timestamp":1637441052364,"user_tz":300,"elapsed":148583,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}},"outputId":"0c4df59f-fda7-42ab-b819-43c58a258c47"},"source":["!brew install wget\n","!wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n","data_path= \"DATAPATH\"\n","%time \n","w2v_model = KeyedVectors.load_word2vec_format('/content/GoogleNews-vectors-negative300.bin.gz', binary=True)\n","print('done loading Word2Vec')"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: brew: command not found\n","--2021-11-20 20:41:43--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n","Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.12.86\n","Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.12.86|:443... connected.\n","HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n","\n","    The file is already fully retrieved; nothing to do.\n","\n","CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n","Wall time: 5.72 µs\n","done loading Word2Vec\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VDV9DXIOCzSr","executionInfo":{"status":"ok","timestamp":1637441062338,"user_tz":300,"elapsed":828,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}},"outputId":"9335c796-247e-4651-d533-8f27e0ad6bb7"},"source":["# Inspect the model\n","word2vec_vocab = w2v_model.vocab.keys()\n","word2vec_vocab_lower = [item.lower() for item in word2vec_vocab]\n","print(len(word2vec_vocab))\n","print(word2vec_vocab_lower[500:1000])"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["3000000\n","['doing', 'face', 'low', 'higher', 'site', 'once', 'yet', 'hours', 'america', 'control', 'received', 'rate', 'career', 'bush', 'teams', 'known', 'offer', 'race', 'ever', 'experience', 'playing', 'name', 'possible', 'countries', 'mr.', 'average', 'together', 'using', '9', 'cut', 'while', 'total', 'round', 'young', 'nearly', 'shares', 'member', 'campaign', 'media', 'needs', 'why', 'house', 'issues', 'costs', 'fire', '##-#', 'victory', 'player', 'began', 'sure', 'story', 'per_cent', 'north', 'his', 'staff', 'order', 'war', 'large', 'interest', 'stock', 'food', 'research', 'key', 'india', 'south', 'morning', 'conference', 'senior', 'global', 'center', 'death', 'person', 'thought', 'gave', 'feel', 'energy', 'history', 'recently', 'largest', 'no.', 'general', 'official', 'released', 'wanted', 'meet', 'short', 'outside', 'running', 'live', 'ball', 'online', 'real', 'position', 'fact', 'fell', 'nine', 'december', 'front', 'action', 'defense', 'problem', 'problems', 'mr', 'nation', 'needed', 'special', 'january', 'almost', 'chance', \"'d\", 'result', 'west', 'september', 'reports', 'leader', 'investment', 'yesterday', 'some', 'leaders', 'ahead', 'production', 'comes', 'no', 'runs', 'match', 'role', 'kind', 'try', 'ended', 'risk', 'areas', 'election', 'workers', 'visit', 'bring', 'road', 'music', 'study', 'makes', 'often', 'release', 'woman', 'vote', 'care', 'town', 'clear', 'comment', 'budget', 'potential', 'single', 'markets', 'policy', 'capital', 'saw', 'access', 'weekend', 'operations', 'whose', 'net', 'house', 'hand', 'increased', 'charges', 'winning', 'trade', 'these', 'income', 'value', 'involved', 'bank', 'november', 'bill', 'compared', 'anything', 'manager', 'texas', 'property', 'stop', 'annual', 'private', 'contract', 'died', 'now', 'hope', 'product', 'fans', 'lower', 'demand', 'news', 'david', 'club', 'comments', 'film', 'yards', 'quality', 'currently', 'events', 'addition', 'couple', 'schools', 'attack', 'region', 'latest', 'opportunity', 'worked', 'course', 'bad', 'fall', 'group', 'october', 'jobs', 'list', 'let', 'however', 'chief', 'summer', 'programs', 'according', 'revenue', 'our', 'rose', 'previous', 'tv', 'football', 'biggest', 'employees', 'changes', 'residents', 'means', 'agreement', 'includes', 'post', 'canada', 'probably', 'related', 'training', 'allowed', 'class', 'bit', 'video', 'michael', 'an', 'sent', 'education', 'states', 'straight', 'love', 'beat', 'hold', 'turn', 'finished', 'network', 'smith', 'buy', 'foreign', 'especially', 'groups', 'wants', 'title', 'included', 'turned', 'bank', 'florida', 'efforts', 'personal', 'businesses', 'august', 'california', 'situation', 'district', 'allow', 'helped', 'body', 'nothing', 'soon', 'safety', 'officer', 'cents', 'europe', 'st.', 'additional', 'spokesman', 'february', 'wife', 'showed', 'leave', 'investors', 'parents', 'medical', 'spending', 'non', 'london', 'council', 'matter', 'spent', 'child', 'world', 'effort', 'opening', 'either', 'range', 'question', 'european', 'goals', 'administration', 'friends', 'himself', 'shows', 'difficult', 'kids', 'paid', 'create', 'cash', 'age', 'league', 'form', 'impact', 'drive', 'someone', 'became', 'stay', 'fight', 'significant', 'firm', 'senate', 'hospital', 'charged', 'operating', 'main', 'book', 'success', 'son', 'trading', '###-####', 'focus', 'room', 'continued', 'congress', 'everything', 'park', 'agency', 'brought', 'talk', 'break', 'air', 'software', 'decided', 'do', 'ready', 'arrested', 'track', 'provides', 'mother', 'base', 'trial', 'phone', 'my', 'build', 'conditions', 'rest', 'johnson', 'terms', 'expect', 'england', 'israel', 'despite', 'closed', 'starting', 'provided', 'pressure', 'lives', 'step', 'remain', 'similar', 'charge', 'date', 'whole', 'land', 'growing', 'james', 'internet', 'projects', 'british', 'cases', 'ground', 'legal', 'international', 'agreed', 'tell', 'test', 'everyone', 'pretty', 'authorities', 'two', 'above', 'moved', 'profit', 'throughout', 'inside', 'ability', 'overall', 'pass', 'officers', 'rather', 'australia', 'actually', 'county', 'amount', 'scheduled', 'themselves', 'organization', 'giving', 'credit', 'father', 'drug', 'investigation', 'families', 'republican', 'funds', 'patients', 'takes', 'systems', 'japan', 'complete', 'sold', 'practice', 'calls', '•', 'uk', 'force', 'student', 'idea', 'reached', 'reason', 'levels', 'space', 'competition', 'forces', 'sector', 'last', 'tried', 'common', 'homes', 'stage', 'department', 'named', 'earnings', 'offers', 'star', 'certain', 'double', 'longer', 'followed', 'cause', 'association', 'signed', 'committee', 'hour', 'college', 'pakistan', 'users', 'iran', 'sign', 'living', 'failed', 'reach', 'quickly', 'receive', 'debt', 'sale', 'board', 'americans', 'road', 'brown', 'insurance', '##:##', 'anyone', 'tournament', 'more', 'gas', 'talks', 'serious', 'required', 'sell', 'construction', 'evidence', 'remains', 'black', 'below', 'improve', 'crisis', 'address', 'questions', 'easy', 'begin', 'view', 'school', 'heard', 'executive', 'raised']\n"]}]},{"cell_type":"code","metadata":{"id":"ZNxlMzpBxxQa","executionInfo":{"status":"ok","timestamp":1637441069261,"user_tz":300,"elapsed":284,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}}},"source":["# Ref: https://www.geeksforgeeks.org/python-os-chdir-method/\n","# Ref: https://stackoverflow.com/questions/9234560/find-all-csv-files-in-a-directory-using-python/12280052 \n","\n","def get_list_filenames(cwd, path, extension):\n","    try:\n","        os.chdir(path)\n","        print(\"Successfully change the directory!\")\n","        filenames = glob.glob('*.{}'.format(extension))\n","        print(\"Number of files: \", len(filenames))\n","\n","    # Caching the exception\n","    except: \n","        print(\"Something wrong with specified directory. Exception- \", sys.exc_info()) \n","\n","    # handling with finally: restore the path which is the current directory before changing directory           \n","    finally: \n","        print(\"Restoring the path\") \n","        os.chdir(cwd) # Change it back to cwd (original directory)\n","        print(\"Current directory is-\", os.getcwd()) \n","        \n","    return filenames\n","\n","\n","# Ref: https://realpython.com/python-keras-text-classification/\n","\n","# Get a list of dataframe after reading all csv files given a path\n","def get_all_image_files_read(path, filenames):\n","    list_img = []\n","    for file in filenames:\n","        img = imageio.imread(path+file)\n","        list_img.append(img)\n","    return list_img"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mc_NGcMjxbSY","executionInfo":{"status":"ok","timestamp":1637441071581,"user_tz":300,"elapsed":324,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}},"outputId":"b73c65bf-b449-4fef-8b72-f2b79e9bc43e"},"source":["%cd /content/drive/MyDrive/American_University/2021_Fall/DATA-642-001_Advanced Machine Learning/data/data_ready/texts/fake\n","!pwd"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/American_University/2021_Fall/DATA-642-001_Advanced Machine Learning/data/data_ready/texts/fake\n","/content/drive/MyDrive/American_University/2021_Fall/DATA-642-001_Advanced Machine Learning/data/data_ready/texts/fake\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k24L2MfGzNim","executionInfo":{"status":"ok","timestamp":1637446460771,"user_tz":300,"elapsed":298,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}},"outputId":"64757ac0-af13-4752-f68c-663125ffba73"},"source":["# initial directory \n","cwd = os.getcwd()\n","path_org = './' # the directory where all the output result are located.\n","extension = 'txt'\n","\n","fake_textfiles = get_list_filenames(cwd, path_org, extension)\n","print(fake_textfiles[0])\n","print(len(fake_textfiles))"],"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully change the directory!\n","Number of files:  4500\n","Restoring the path\n","Current directory is- /content/drive/My Drive/American_University/2021_Fall/DATA-642-001_Advanced Machine Learning/data/data_ready/texts/fake\n","FAKE_BCD3501.txt\n","4500\n"]}]},{"cell_type":"markdown","metadata":{"id":"UxS8xguiGKci"},"source":["- 360 from B fake videos\n","- 1884 from C fake videos\n","- 2256 from D fake videos\n","\n","Totally 4500 text files"]},{"cell_type":"code","metadata":{"id":"Gy7utHk0yIq5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637441199917,"user_tz":300,"elapsed":287,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}},"outputId":"ce608a4e-79f0-411a-aacc-64fcdef5053c"},"source":["print(fake_textfiles[2300])"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["FAKE_BCD1801.txt\n"]}]},{"cell_type":"markdown","metadata":{"id":"1W5v_O0aPY1C"},"source":["# Tokenize and Remove Stopwords\n","- Keeping punctuations could be relevant for this task"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tcOBvvG-Gmj5","executionInfo":{"status":"ok","timestamp":1637443925369,"user_tz":300,"elapsed":301,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}},"outputId":"56c3f501-509b-47b8-d170-4a84979015a0"},"source":["aaa = []\n","aaa.append(open(fake_textfiles[2300]).readline())\n","print(aaa)\n","\n","mystopwords = set(stopwords.words(\"english\"))\n","# function to tokenize tweets, remove stopwords and numbers.\n","#k eeping punctuations and emoticon symbols could be relevant for this task!\n","def preprocess_corpus(texts):\n","  def remove_stops_digits(tokens):\n","  #Nested function that removes stopwords and digits from a list of tokens\n","    return [token for token in tokens if token not in mystopwords and not token.isdigit()]\n","    #This return statement below uses the above function to process twitter tokenizer output further.\n","  return [remove_stops_digits(word_tokenize(content)) for content in texts]\n","\n","\n","bbb = preprocess_corpus(aaa)\n","flatten_list = sum(bbb, [])\n","print(flatten_list)\n"],"execution_count":79,"outputs":[{"output_type":"stream","name":"stdout","text":["[\"to the point where okay I'm going to go this way and you go this way because the camera has this this way in\"]\n","['point', 'okay', 'I', \"'m\", 'going', 'go', 'way', 'go', 'way', 'camera', 'way']\n","point  :  point\n","okay  :  okay\n","I  :  I\n","'m  :  'm\n","going  :  go\n","go  :  go\n","way  :  way\n","go  :  go\n","way  :  way\n","camera  :  camera\n","way  :  way\n","['point', 'okay', 'I', \"'m\", 'going', 'go', 'way', 'go', 'way', 'camera', 'way']\n"]}]},{"cell_type":"markdown","metadata":{"id":"Wbh9kkrudxZo"},"source":["# Create **word2vec** Vetorzation Function"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"id":"iAxtLbHDMtcC","executionInfo":{"status":"ok","timestamp":1637447633221,"user_tz":300,"elapsed":311,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}},"outputId":"a0be91fb-7db7-4c50-d15d-40e4cad6617c"},"source":["# Creating a feature vector by averaging all embeddings for all sentences\n","def embedding_feats(list_of_lists):\n","  DIMENSION = 300\n","  zero_vector = np.zeros(DIMENSION)\n","  feats = []\n","  for tokens in list_of_lists:\n","    feat_for_this = np.zeros(DIMENSION)\n","    count_for_this = 0\n","    for token in tokens:\n","      if token in w2v_model:\n","        feat_for_this += w2v_model[token]\n","        count_for_this +=1\n","    feats.append(feat_for_this/count_for_this)\n","  return feats\n","\n","\"\"\"\n","train_vector = embedding_feats(flatten_list)\n","train_vector = np.array(train_vector)\n","print(train_vector.shape)\n","print(train_vector)\n","\n","flaa = np.ndarray.flatten(train_vector)\n","print(flaa.shape)\n","print(flaa)\n","\"\"\""],"execution_count":88,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\ntrain_vector = embedding_feats(flatten_list)\\ntrain_vector = np.array(train_vector)\\nprint(train_vector.shape)\\nprint(train_vector)\\n\\nflaa = np.ndarray.flatten(train_vector)\\nprint(flaa.shape)\\nprint(flaa)\\n'"]},"metadata":{},"execution_count":88}]},{"cell_type":"markdown","metadata":{"id":"C8MugjA4cF3G"},"source":["# create `FAKE_RTVC_B` text features\n","- total frames: 360 videos * 4 frames = 1440"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HN54hJLQZuQY","executionInfo":{"status":"ok","timestamp":1637448207445,"user_tz":300,"elapsed":1010,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}},"outputId":"7a8ea7b6-120f-4b47-91f7-c280a5186768"},"source":["fake_B = []\n","for i in range(0, 360):\n","  tmp = []\n","  tmp.append(open(fake_textfiles[i]).readline())\n","  # apply to function\n","  tmp = preprocess_corpus(tmp)\n","  # faltten 2d list to 1d\n","  tmp = sum(tmp, [])\n","  text_vectors = embedding_feats(tmp)\n","  text_vectors = np.array(text_vectors, dtype=object)\n","  text_vectors = np.ndarray.flatten(text_vectors)\n","  print(text_vectors.shape)\n","  del tmp\n","  fake_B.append(text_vectors)"],"execution_count":98,"outputs":[{"output_type":"stream","name":"stdout","text":["(300,)\n","(3600,)\n","(300,)\n","(300,)\n","(1500,)\n","(300,)\n","(3600,)\n","(2400,)\n","(300,)\n","(2400,)\n","(1200,)\n","(2100,)\n","(2100,)\n","(2100,)\n","(2100,)\n","(2100,)\n","(2100,)\n","(2100,)\n","(2100,)\n","(2100,)\n","(2100,)\n","(5400,)\n","(5400,)\n","(5400,)\n","(1500,)\n","(3000,)\n","(3000,)\n","(1500,)\n","(3000,)\n","(3000,)\n","(3000,)\n","(5400,)\n","(1500,)\n","(1500,)\n","(1500,)\n","(5400,)\n","(3000,)\n","(1500,)\n","(1500,)\n","(3000,)\n","(1500,)\n","(5400,)\n","(3000,)\n","(5400,)\n","(5400,)\n","(3000,)\n","(3900,)\n","(1500,)\n","(1500,)\n","(3000,)\n","(5400,)\n","(5400,)\n","(1200,)\n","(2100,)\n","(3900,)\n","(6900,)\n","(3900,)\n","(6900,)\n","(6900,)\n","(6900,)\n","(6900,)\n","(3900,)\n","(6900,)\n","(3900,)\n","(3900,)\n","(6900,)\n","(6900,)\n","(3900,)\n","(6900,)\n","(3900,)\n","(3900,)\n","(6900,)\n","(3900,)\n","(3900,)\n","(1500,)\n","(300,)\n","(2400,)\n","(3900,)\n","(2400,)\n","(2400,)\n","(2400,)\n","(2400,)\n","(2400,)\n","(2400,)\n","(2400,)\n","(2400,)\n","(2400,)\n","(2400,)\n","(2100,)\n","(2100,)\n","(2100,)\n","(2100,)\n","(2100,)\n","(2100,)\n","(2100,)\n","(2100,)\n","(2100,)\n","(2100,)\n","(3000,)\n","(3000,)\n","(1200,)\n","(3000,)\n","(3000,)\n","(3000,)\n","(3000,)\n","(3000,)\n","(3000,)\n","(3000,)\n","(3000,)\n","(2100,)\n","(2100,)\n","(2100,)\n","(2100,)\n","(2100,)\n","(2100,)\n","(2100,)\n","(2100,)\n","(2100,)\n","(2100,)\n","(6000,)\n","(1200,)\n","(1500,)\n","(3000,)\n","(3000,)\n","(3000,)\n","(3000,)\n","(3000,)\n","(3000,)\n","(3000,)\n","(3000,)\n","(3000,)\n","(3000,)\n","(4500,)\n","(4500,)\n","(4500,)\n","(4500,)\n","(4500,)\n","(4500,)\n","(4500,)\n","(4500,)\n","(4500,)\n","(2700,)\n","(4500,)\n","(2700,)\n","(2700,)\n","(2700,)\n","(2700,)\n","(2700,)\n","(2700,)\n","(2700,)\n","(2700,)\n","(2700,)\n","(3300,)\n","(3300,)\n","(3300,)\n","(3300,)\n","(3300,)\n","(3300,)\n","(3300,)\n","(3300,)\n","(3300,)\n","(3300,)\n","(3900,)\n","(5700,)\n","(2100,)\n","(1800,)\n","(1800,)\n","(1800,)\n","(1800,)\n","(1800,)\n","(1800,)\n","(1800,)\n","(1800,)\n","(1800,)\n","(1800,)\n","(2100,)\n","(2400,)\n","(2400,)\n","(2400,)\n","(2400,)\n","(2400,)\n","(2400,)\n","(2400,)\n","(2400,)\n","(2400,)\n","(2400,)\n","(5400,)\n","(5400,)\n","(5400,)\n","(5400,)\n","(5400,)\n","(5400,)\n","(5400,)\n","(5400,)\n","(5400,)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in true_divide\n","  del sys.path[0]\n"]},{"output_type":"stream","name":"stdout","text":["(5400,)\n","(2700,)\n","(2700,)\n","(5400,)\n","(2700,)\n","(2700,)\n","(2700,)\n","(2700,)\n","(2700,)\n","(2700,)\n","(2700,)\n","(2700,)\n","(2100,)\n","(3000,)\n","(3000,)\n","(3000,)\n","(3000,)\n","(3000,)\n","(3000,)\n","(3000,)\n","(3000,)\n","(3000,)\n","(4200,)\n","(3000,)\n","(4200,)\n","(4200,)\n","(4200,)\n","(4200,)\n","(4200,)\n","(4200,)\n","(4200,)\n","(4200,)\n","(4200,)\n","(5400,)\n","(5400,)\n","(5400,)\n","(5400,)\n","(5400,)\n","(5400,)\n","(5400,)\n","(5400,)\n","(5400,)\n","(5400,)\n","(900,)\n","(900,)\n","(900,)\n","(900,)\n","(900,)\n","(900,)\n","(900,)\n","(900,)\n","(900,)\n","(300,)\n","(900,)\n","(300,)\n","(300,)\n","(300,)\n","(300,)\n","(300,)\n","(300,)\n","(300,)\n","(300,)\n","(300,)\n","(2100,)\n","(1200,)\n","(6300,)\n","(6300,)\n","(6300,)\n","(6300,)\n","(6300,)\n","(6300,)\n","(6300,)\n","(6300,)\n","(6300,)\n","(6300,)\n","(5700,)\n","(5700,)\n","(5700,)\n","(5700,)\n","(5700,)\n","(5700,)\n","(5700,)\n","(5700,)\n","(5700,)\n","(300,)\n","(5700,)\n","(6300,)\n","(6300,)\n","(6300,)\n","(300,)\n","(300,)\n","(6300,)\n","(300,)\n","(300,)\n","(300,)\n","(6300,)\n","(300,)\n","(300,)\n","(6300,)\n","(300,)\n","(6300,)\n","(300,)\n","(6300,)\n","(6300,)\n","(6300,)\n","(2700,)\n","(300,)\n","(1800,)\n","(1800,)\n","(1800,)\n","(1800,)\n","(1800,)\n","(1800,)\n","(1800,)\n","(1800,)\n","(1800,)\n","(1800,)\n","(3300,)\n","(3600,)\n","(1200,)\n","(3000,)\n","(2100,)\n","(2100,)\n","(2100,)\n","(2100,)\n","(2100,)\n","(2100,)\n","(2100,)\n","(2100,)\n","(2100,)\n","(2100,)\n","(2400,)\n","(3300,)\n","(1500,)\n","(1500,)\n","(1500,)\n","(1500,)\n","(1500,)\n","(1500,)\n","(1500,)\n","(1500,)\n","(1500,)\n","(1500,)\n","(3600,)\n","(3600,)\n","(3600,)\n","(3600,)\n","(3600,)\n","(3600,)\n","(3600,)\n","(3600,)\n","(3600,)\n","(3600,)\n","(3600,)\n","(2400,)\n","(900,)\n","(900,)\n","(900,)\n","(900,)\n","(900,)\n","(900,)\n","(900,)\n","(900,)\n","(900,)\n","(1500,)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fsh83e9Qf9Rh","executionInfo":{"status":"ok","timestamp":1637448211796,"user_tz":300,"elapsed":313,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}},"outputId":"a05d30bc-0386-4533-e911-afe743d13d72"},"source":["print(len(fake_B))\n","#print(fake_B[100])\n","\n","# Because we capture 4 frame in fake B set, so we need to duplicate the text 4 times \n","B = np.concatenate((fake_B, fake_B, fake_B, fake_B), axis = 0)\n","print(len(B))"],"execution_count":99,"outputs":[{"output_type":"stream","name":"stdout","text":["360\n","1440\n"]},{"output_type":"stream","name":"stderr","text":["<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"]}]},{"cell_type":"markdown","metadata":{"id":"yJQZv9V6hTDf"},"source":["# Create `FAKE_FSGAN_C` to text features\n","- total frames: 1884 videos * 2 frames = 3768"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yxu6_FpNhev2","outputId":"4b731958-152b-4096-c3d0-7a4df99eb95a"},"source":["fake_C = []\n","for i in range(360, 2244):\n","  tmp = []\n","  tmp.append(open(fake_textfiles[i]).readline())\n","  # apply to function\n","  tmp = preprocess_corpus(tmp)\n","  # faltten 2d list to 1d\n","  tmp = sum(tmp, [])\n","  text_vectors = embedding_feats(tmp)\n","  text_vectors = np.array(text_vectors, dtype=object)\n","  text_vectors = np.ndarray.flatten(text_vectors)\n","  print(text_vectors.shape)\n","  del tmp\n","  fake_C.append(text_vectors)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(1500,)\n","(1500,)\n","(900,)\n","(1500,)\n","(1500,)\n","(1500,)\n","(1500,)\n","(1500,)\n","(900,)\n","(2400,)\n","(1500,)\n","(1500,)\n","(2400,)\n","(3600,)\n","(3000,)\n","(3000,)\n","(3000,)\n","(3000,)\n","(3000,)\n","(3000,)\n","(3000,)\n","(3000,)\n","(1800,)\n","(3000,)\n","(3000,)\n","(600,)\n","(6300,)\n","(4800,)\n","(1500,)\n","(5100,)\n","(5100,)\n","(1500,)\n","(1500,)\n","(4800,)\n","(4800,)\n","(1500,)\n","(4800,)\n","(1500,)\n","(4800,)\n","(1500,)\n","(1500,)\n","(1500,)\n","(1500,)\n","(1500,)\n","(4800,)\n","(4800,)\n","(4800,)\n","(2400,)\n","(2400,)\n","(2400,)\n","(2100,)\n","(2400,)\n","(2400,)\n","(2100,)\n","(2400,)\n","(2400,)\n","(2400,)\n","(3300,)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in true_divide\n","  del sys.path[0]\n"]},{"output_type":"stream","name":"stdout","text":["(2400,)\n","(3900,)\n","(3300,)\n","(8100,)\n","(2400,)\n","(3900,)\n","(2400,)\n","(600,)\n","(600,)\n","(3900,)\n","(600,)\n","(9900,)\n","(9900,)\n","(2100,)\n","(9900,)\n","(1500,)\n","(3900,)\n","(1500,)\n","(1500,)\n","(9900,)\n","(9900,)\n","(1500,)\n","(600,)\n","(600,)\n","(2100,)\n","(5700,)\n","(9900,)\n","(600,)\n","(600,)\n","(5700,)\n","(5700,)\n","(1500,)\n","(3300,)\n","(3300,)\n","(3900,)\n","(1200,)\n","(9900,)\n","(3900,)\n","(600,)\n","(600,)\n","(9900,)\n","(600,)\n","(600,)\n","(600,)\n","(2400,)\n","(3900,)\n","(3900,)\n","(3900,)\n","(2400,)\n","(600,)\n","(600,)\n","(3300,)\n","(2400,)\n","(3900,)\n","(3900,)\n","(5700,)\n","(5700,)\n","(3900,)\n","(3300,)\n","(3900,)\n","(3300,)\n","(9900,)\n","(3900,)\n","(2400,)\n","(3900,)\n","(2400,)\n","(2400,)\n","(2400,)\n","(9900,)\n","(2100,)\n","(3900,)\n","(2400,)\n","(2400,)\n","(2100,)\n","(3300,)\n","(2100,)\n","(3300,)\n","(3300,)\n","(3300,)\n","(3900,)\n","(3300,)\n","(900,)\n","(2100,)\n","(2100,)\n","(1500,)\n","(5100,)\n","(3600,)\n","(3300,)\n","(3000,)\n","(300,)\n","(2100,)\n","(3300,)\n","(3600,)\n","(3300,)\n","(2400,)\n","(900,)\n","(7800,)\n","(2100,)\n","(1800,)\n","(2100,)\n","(2100,)\n","(4500,)\n","(2100,)\n","(2400,)\n","(4200,)\n","(5400,)\n","(1200,)\n","(3600,)\n","(3000,)\n","(1500,)\n","(900,)\n","(2700,)\n","(1200,)\n","(3900,)\n","(2400,)\n","(3300,)\n","(3000,)\n","(300,)\n","(5100,)\n","(2700,)\n","(2400,)\n","(2400,)\n","(4200,)\n","(1800,)\n","(2400,)\n","(2400,)\n","(1800,)\n","(2100,)\n","(1500,)\n","(300,)\n","(900,)\n","(3300,)\n","(2400,)\n","(2700,)\n","(3900,)\n","(3000,)\n","(1500,)\n","(3000,)\n","(3300,)\n","(2700,)\n","(4500,)\n","(2400,)\n","(3600,)\n","(6300,)\n","(300,)\n","(2100,)\n","(3000,)\n","(2400,)\n","(2700,)\n","(4200,)\n","(3000,)\n","(3600,)\n","(3600,)\n","(3300,)\n","(3000,)\n","(3300,)\n","(5100,)\n","(3600,)\n","(1200,)\n","(3300,)\n","(2100,)\n","(4200,)\n","(2100,)\n","(1500,)\n","(2100,)\n","(1800,)\n","(7200,)\n","(3000,)\n","(2700,)\n","(3900,)\n","(2100,)\n","(1800,)\n","(5100,)\n","(3300,)\n","(3300,)\n","(5400,)\n","(1500,)\n","(3000,)\n","(4200,)\n","(2400,)\n","(1500,)\n","(2100,)\n","(3000,)\n","(1200,)\n","(4500,)\n","(3300,)\n","(4200,)\n","(3600,)\n","(1500,)\n","(3000,)\n","(2700,)\n","(5100,)\n","(2700,)\n","(1200,)\n","(6600,)\n","(1800,)\n","(8700,)\n","(1500,)\n","(3600,)\n","(1200,)\n","(3600,)\n","(3600,)\n","(3600,)\n","(300,)\n","(1800,)\n","(3600,)\n","(3000,)\n","(2100,)\n","(2100,)\n","(3300,)\n","(1500,)\n","(1800,)\n","(300,)\n","(3000,)\n","(1200,)\n","(2400,)\n","(2700,)\n","(2100,)\n","(3300,)\n","(1200,)\n","(2400,)\n","(4500,)\n","(6600,)\n","(2400,)\n","(900,)\n","(2400,)\n","(3000,)\n","(1200,)\n","(2100,)\n","(2400,)\n","(2400,)\n","(2700,)\n","(2400,)\n","(3000,)\n","(3000,)\n","(2100,)\n","(1800,)\n","(1800,)\n","(1800,)\n","(5400,)\n","(5700,)\n","(3000,)\n","(2400,)\n","(3900,)\n","(2100,)\n","(1200,)\n","(2700,)\n","(2400,)\n","(3300,)\n","(4500,)\n","(1200,)\n","(2100,)\n","(1200,)\n","(3600,)\n","(6900,)\n","(1800,)\n","(3300,)\n","(4500,)\n","(2100,)\n","(2700,)\n","(9900,)\n","(900,)\n","(5700,)\n","(2400,)\n","(3600,)\n","(3300,)\n","(2700,)\n","(1200,)\n","(2400,)\n","(2400,)\n","(300,)\n","(3900,)\n","(3000,)\n","(4500,)\n","(300,)\n","(4200,)\n","(2400,)\n","(2100,)\n","(1200,)\n","(5100,)\n","(5100,)\n","(3000,)\n","(3000,)\n","(3000,)\n","(3900,)\n","(5400,)\n","(4200,)\n","(3600,)\n","(1200,)\n","(1800,)\n","(2100,)\n","(1500,)\n","(2100,)\n","(1800,)\n","(4200,)\n","(300,)\n","(3000,)\n","(1500,)\n","(5400,)\n","(3300,)\n","(1500,)\n","(1500,)\n","(5100,)\n","(5700,)\n","(4500,)\n","(2700,)\n","(6000,)\n","(2400,)\n","(6300,)\n","(1800,)\n","(1500,)\n","(4500,)\n","(4800,)\n","(3600,)\n","(2700,)\n","(2700,)\n","(4200,)\n","(1800,)\n","(6000,)\n","(3000,)\n","(2400,)\n","(2700,)\n","(6900,)\n","(4500,)\n","(2700,)\n","(4200,)\n","(3000,)\n","(3300,)\n","(1500,)\n","(4500,)\n","(1500,)\n","(3000,)\n","(3300,)\n","(2400,)\n","(2700,)\n","(4800,)\n","(2400,)\n","(1500,)\n","(1800,)\n","(1800,)\n","(2700,)\n","(300,)\n","(4200,)\n","(3300,)\n","(2100,)\n","(3600,)\n","(3600,)\n","(3000,)\n","(1800,)\n","(1200,)\n","(7800,)\n","(3300,)\n","(3600,)\n","(4500,)\n","(1800,)\n","(900,)\n","(2700,)\n","(2700,)\n","(1500,)\n","(2100,)\n","(2100,)\n","(1800,)\n","(4200,)\n","(3600,)\n","(3000,)\n","(3000,)\n","(2100,)\n","(6000,)\n","(2700,)\n","(3900,)\n","(3600,)\n","(2400,)\n","(5700,)\n","(600,)\n","(5100,)\n","(2100,)\n","(5100,)\n","(2700,)\n","(3300,)\n","(2100,)\n","(2100,)\n","(1800,)\n","(1800,)\n","(1800,)\n","(2400,)\n","(2100,)\n","(1800,)\n","(6000,)\n","(3000,)\n","(900,)\n","(4800,)\n","(3000,)\n","(1800,)\n","(8400,)\n","(3300,)\n","(1500,)\n","(1500,)\n","(3000,)\n","(4200,)\n","(2100,)\n","(2400,)\n","(3000,)\n","(2700,)\n","(3300,)\n","(6000,)\n","(300,)\n","(6300,)\n","(5100,)\n","(2400,)\n","(3900,)\n","(900,)\n","(3300,)\n","(3600,)\n","(2400,)\n","(4800,)\n","(4800,)\n","(4500,)\n","(2700,)\n","(3600,)\n","(1500,)\n","(5400,)\n","(2400,)\n","(3000,)\n","(2700,)\n","(3300,)\n","(6000,)\n","(1200,)\n","(8700,)\n","(2700,)\n","(2400,)\n","(2400,)\n","(3300,)\n","(4500,)\n","(5100,)\n","(3900,)\n","(2100,)\n","(1200,)\n","(2700,)\n","(1500,)\n","(2700,)\n","(4200,)\n","(4800,)\n","(900,)\n","(3600,)\n","(3600,)\n","(3600,)\n","(900,)\n","(900,)\n","(5400,)\n","(900,)\n","(3600,)\n","(5400,)\n","(3600,)\n","(900,)\n","(900,)\n","(900,)\n","(5400,)\n","(5400,)\n","(5400,)\n","(900,)\n","(900,)\n","(3600,)\n","(5400,)\n","(5400,)\n","(9900,)\n","(900,)\n","(2400,)\n","(1200,)\n","(2400,)\n","(2400,)\n","(2400,)\n","(2400,)\n","(2400,)\n","(2400,)\n","(2400,)\n","(2400,)\n","(1500,)\n","(2400,)\n","(1500,)\n","(2400,)\n","(1200,)\n","(1800,)\n","(3600,)\n","(3600,)\n","(3600,)\n","(2700,)\n","(3600,)\n","(4500,)\n","(1800,)\n","(4500,)\n","(2700,)\n","(4500,)\n","(1800,)\n","(1800,)\n","(1800,)\n","(3600,)\n","(3600,)\n","(2700,)\n","(3600,)\n","(3600,)\n","(2700,)\n","(4500,)\n","(4500,)\n","(4500,)\n","(3600,)\n","(3600,)\n","(3600,)\n","(1800,)\n","(1800,)\n","(2700,)\n","(1800,)\n","(1800,)\n","(1800,)\n","(2700,)\n","(3600,)\n","(4200,)\n","(4500,)\n","(3600,)\n","(600,)\n","(4500,)\n","(4500,)\n","(4500,)\n","(2700,)\n","(4500,)\n","(4200,)\n","(3600,)\n","(900,)\n","(5100,)\n","(3600,)\n","(300,)\n","(300,)\n","(300,)\n","(300,)\n","(300,)\n","(300,)\n","(300,)\n","(300,)\n","(300,)\n","(300,)\n","(3000,)\n","(1200,)\n","(1800,)\n","(2400,)\n","(1800,)\n","(3300,)\n","(3300,)\n","(3300,)\n","(4800,)\n","(1800,)\n","(4800,)\n","(4800,)\n","(2400,)\n","(1800,)\n","(2400,)\n","(4500,)\n","(4500,)\n","(4500,)\n","(2400,)\n","(4800,)\n","(4500,)\n","(1800,)\n","(1800,)\n","(4500,)\n","(4500,)\n","(2400,)\n","(1800,)\n","(4800,)\n","(4800,)\n","(2400,)\n","(1800,)\n","(2400,)\n","(1500,)\n","(1800,)\n","(3300,)\n","(1500,)\n","(1500,)\n","(1500,)\n","(1500,)\n","(4500,)\n","(4500,)\n","(2100,)\n","(4800,)\n","(2400,)\n"]}]},{"cell_type":"code","metadata":{"id":"qHOTsi4YhtBO"},"source":["print(len(fake_C))\n","#print(fake_B[100])\n","\n","# Because we capture 2 frame in fake C set , so we need to duplicate the text 2 times \n","C = np.concatenate((fake_C, fake_C), axis = 0)\n","print(len(C))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qjtMg4J_iVq3"},"source":["# Create `FAKE_FACESWAP_D_W2L` to text features\n","- total frames: 2256 videos * 2 frames = 4512"]},{"cell_type":"code","metadata":{"id":"bFlfBDqdie3k"},"source":["fake_D = []\n","for i in range(2244, len(fake_textfiles)):\n","  tmp = []\n","  tmp.append(open(fake_textfiles[i]).readline())\n","  # apply to function\n","  tmp = preprocess_corpus(tmp)\n","  # faltten 2d list to 1d\n","  tmp = sum(tmp, [])\n","  text_vectors = embedding_feats(tmp)\n","  text_vectors = np.array(text_vectors, dtype=object)\n","  text_vectors = np.ndarray.flatten(text_vectors)\n","  print(text_vectors.shape)\n","  del tmp\n","  fake_D.append(text_vectors)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GdD2w9dniero"},"source":["print(len(fake_D))\n","#print(fake_B[100])\n","\n","# Because we capture 2 frame in fake C set , so we need to duplicate the text 2 times \n","D = np.concatenate((fake_D, fake_D), axis = 0)\n","print(len(D))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X8-LVqZRHUng"},"source":["# References\n","- https://code.google.com/archive/p/word2vec/"]}]}